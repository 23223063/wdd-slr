@inproceedings{10.1145/3368926.3369730,
author = {Hoang, Xuan Dau and Nguyen, Ngoc Tuong},
title = {A Multi-layer Model for Website Defacement Detection},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369730},
doi = {10.1145/3368926.3369730},
abstract = {Website defacements have long been considered one of major threats to websites and web portals of enterprises and government organizations. Defacement attacks can bring in serious consequences to website owners, including immediate interruption of website operations and damage of the owner reputation, which may lead huge financial losses. Many solutions have been researched and deployed for monitoring and detection of defacement attacks, such as those based on checksum comparison, diff comparison, DOM tree analysis and advanced methods. However, some solutions only work on static web pages and some others demand extensive computing resources. This paper proposes a multi-layer model for website defacement detection. The proposed model is based on three layers of machine learning-based detection for web text content and a layer for checking the integrity of embedded images in the web pages. Our experiments show that the proposed model produces the overall detection accuracy of more than 98.8% and the false positive rate of less than 1.04% for all tested cases.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {508–513},
numpages = {6},
keywords = {Website Defacement Monitoring and Detection, Website Defacement Attack, Multi-layer Defacement Detection, Machine Learning-based Defacement Detection},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@inproceedings{10.1145/3287921.3287975,
author = {Hoang, Xuan Dau},
title = {A Website Defacement Detection Method Based on Machine Learning Techniques},
year = {2018},
isbn = {9781450365390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287921.3287975},
doi = {10.1145/3287921.3287975},
abstract = {Website defacement attacks have been one of major threats to websites and web portals of private and public organizations. The attacks can cause serious consequences to website owners, including interrupting the website operations and damaging the owner's reputation, which may lead to big financial losses. A number of techniques have been proposed for website defacement monitoring and detection, such as checksum comparison, diff comparison, DOM tree analysis and complex algorithms. However, some of them only work on static web pages and the others require extensive computational resources. In this paper, we propose a machine learning-based method for website defacement detection. In our method, machine learning techniques are used to build classifiers (detection profile) for page classification into either Normal or Attacked class. As the detection profile can be learned from training data, our method can work well for both static and dynamic web pages. Experimental results show that our approach achieves high detection accuracy of over 93% and low false positive rate of less than 1%. In addition, our method does not require extensive computational resources, so it is practical for online deployment.},
booktitle = {Proceedings of the 9th International Symposium on Information and Communication Technology},
pages = {443–448},
numpages = {6},
keywords = {Website Defacement Detection, Website Defacement Attack, Machine Learning-based Attack Detection, Anomaly-based Attack Detection},
location = {Danang City, Viet Nam},
series = {SoICT '18}
}

@inproceedings{10.1145/3196494.3196542,
author = {Maggi, Federico and Balduzzi, Marco and Flores, Ryan and Gu, Lion and Ciancaglini, Vincenzo},
title = {Investigating Web Defacement Campaigns at Large},
year = {2018},
isbn = {9781450355766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196494.3196542},
doi = {10.1145/3196494.3196542},
abstract = {Website defacement is the practice of altering the web pages of a website after its compromise. The altered pages, calleddeface pages, can negatively affect the reputation and business of the victim site. Previous research has focused primarily on detection, rather than exploring the defacement phenomenon in depth. While investigating several defacements, we observed that the artifacts left by the defacers allow an expert analyst to investigate the actors' modus operandi and social structure, and expand from the single deface page to a group of related defacements (i.e., acampaign ). However, manually performing such analysis on millions of incidents is tedious, and poses scalability challenges. From these observations, we propose an automated approach that efficiently builds intelligence information out of raw deface pages. Our approach streamlines the analysts job by automatically recognizing defacement campaigns, and assigning meaningful textual labels to them. Applied to a comprehensive dataset of 13 million defacement records, from Jan. 1998 to Sept. 2016, our approach allowed us to conduct the first large-scale measurement on web defacement campaigns. In addition, our approach is meant to be adopted operationally by analysts to identify live campaigns on the field.We go beyond confirming anecdotal evidence. We analyze the social structure of modern defacers, which includes lone individuals as well as actors that cooperate with each others, or with teams, which evolve over time and dominate the scene. We conclude by drawing a parallel between the time line of World-shaping events and defacement campaigns, representing the evolution of the interests and orientation of modern defacers.},
booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
pages = {443–456},
numpages = {14},
keywords = {web defacement, web attacks, online hacktivism},
location = {Incheon, Republic of Korea},
series = {ASIACCS '18}
}

@inproceedings{10.1145/3589334.3645401,
author = {Vu, Anh V. and Thomas, Daniel R. and Collier, Ben and Hutchings, Alice and Clayton, Richard and Anderson, Ross},
title = {Getting Bored of Cyberwar: Exploring the Role of Low-level Cybercrime Actors in the Russia-Ukraine Conflict},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645401},
doi = {10.1145/3589334.3645401},
abstract = {There has been substantial commentary on the role of cyberattacks carried out by low-level cybercrime actors in the Russia-Ukraine conflict. We analyse 358k website defacement attacks, 1.7M UDP amplification DDoS attacks, 1764 posts made by 372 users on Hack Forums mentioning the two countries, and 441 Telegram announcements (with 58k replies) of a volunteer hacking group for two months before and four months after the invasion. We find the conflict briefly but notably caught the attention of low-level cybercrime actors, with significant increases in online discussion and both types of attacks targeting Russia and Ukraine. However, there was little evidence of high-profile actions; the role of these players in the ongoing hybrid warfare is minor, and they should be separated from persistent and motivated 'hacktivists' in state-sponsored operations. Their involvement in the conflict appears to have been short-lived and fleeting, with a clear loss of interest in discussing the situation and carrying out both website defacement and DDoS attacks against either Russia or Ukraine after just a few weeks.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1596–1607},
numpages = {12},
keywords = {cybercrime, cyberwar, ddos attacks, it army of ukraine, russia-ukraine conflict, volunteer hacktivists, website defacement attacks},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3543507.3583377,
author = {Zhao, Rui},
title = {The Chameleon on the Web: an Empirical Study of the Insidious Proactive Web Defacements},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583377},
doi = {10.1145/3543507.3583377},
abstract = {Web defacement is one of the major promotional channels for online underground economies. It regularly compromises benign websites and injects fraudulent content to promote illicit goods and services. It inflicts significant harm to websites’ reputations and revenues and may lead to legal ramifications. In this paper, we uncover proactive web defacements, where the involved web pages (i.e., landing pages) proactively deface themselves within browsers using JavaScript (i.e., control scripts). Proactive web defacements have not yet received attention from research communities, anti-hacking organizations, or law-enforcement officials. To detect proactive web defacements, we designed a practical tool, PACTOR. It runs in the browser and intercepts JavaScript API calls that manipulate web page content. It takes snapshots of the rendered HTML source code immediately before and after the intercepted API calls and detects proactive web defacements by visually comparing every two consecutive snapshots. Our two-month empirical study, using PACTOR, on 2,454 incidents of proactive web defacements shows that they can evade existing URL safety-checking tools and effectively promote the ranking of their landing pages using legitimate content/keywords. We also investigated the vendor network of proactive web defacements and reported all the involved domains to law-enforcement officials and URL-safety checking tools.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2241–2251},
numpages = {11},
keywords = {proactive, security, trust, web defacement},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3655693.3655713,
author = {Pfaller, Tobias and Skopik, Florian and Smith, Paul and Leitner, Maria},
title = {Towards Customized Cyber Exercises using a Process-based Lifecycle Model},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655693.3655713},
doi = {10.1145/3655693.3655713},
abstract = {Cyber exercises enable the effective training of cyber security skills in a simulated, yet realistic, environment for a wide variety of professional roles. However, planning, conducting, and evaluating customized (i.e., non-standard) cyber exercise scenarios involves numerous time- and resource-intensive activities, which are still mostly carried out manually today. Unfortunately, the high costs related to these activities limit the practical applicability of cyber exercises to serve widely as a regular tool for skill development. Today, the flow of cyber exercise scenarios usually consists of predefined and meticulously planned injects (e.g. events) that are sequentially rolled out and thus drive the exercise. The composition of such injects resembles a linear process in its simplest form. Therefore, we argue that the utilization of existing, standardized, and well-researched methods from the business process domain provides opportunities to improve the quality of cyber exercises and at the same time reduce the workload necessary for planning and conducting them. This paper reviews the challenges related to conducting customized cyber exercises and introduces a process-based cyber exercise lifecycle model that leverages the power of process modeling languages, process engines, and process mining tools to transform cyber exercises into transparent, dynamic, and highly automated endeavors. We further describe the application of this lifecycle model in course of a proof-of-concept implementation and discuss lessons learned from its utilization at a large-scale national cyber exercise together with CERTs and authorities. While the state of the art mostly focuses on optimizing individual tasks or phases within the cyber exercise lifecycle, our contribution aims to offer a comprehensive integrated framework that spans across the phases, providing interfaces between them, and enhancing the overall effectiveness and maintainability of cyber exercises.},
booktitle = {Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
pages = {37–45},
numpages = {9},
keywords = {Cyber Exercise, Cyber Exercise Lifecycle, Cyber Exercise Scenario, Cyber Range, Process Engine},
location = {Xanthi, Greece},
series = {EICC '24}
}

@inproceedings{10.1145/3366423.3380165,
author = {Elyashar, Aviad and Uziel, Sagi and Paradise, Abigail and Puzis, Rami},
title = {The Chameleon Attack: Manipulating Content Display in Online Social Media},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380165},
doi = {10.1145/3366423.3380165},
abstract = {Online social networks (OSNs) are ubiquitous attracting millions of users all over the world. Being a popular communication media OSNs are exploited in a variety of cyber-attacks. In this article, we discuss the chameleon attack technique, a new type of OSN-based trickery where malicious posts and profiles change the way they are displayed to OSN users to conceal themselves before the attack or avoid detection. Using this technique, adversaries can, for example, avoid censorship by concealing true content when it is about to be inspected; acquire social capital to promote new content while piggybacking a trending one; cause embarrassment and serious reputation damage by tricking a victim to like, retweet, or comment a message that he wouldn’t normally do without any indication for the trickery within the OSN. An experiment performed with closed Facebook groups of sports fans shows that (1) chameleon pages can pass by the moderation filters by changing the way their posts are displayed and (2) moderators do not distinguish between regular and chameleon pages. We list the OSN weaknesses that facilitate the chameleon attack and propose a set of mitigation guidelines.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {848–859},
numpages = {12},
keywords = {Online Social Networks, Link Previews, Chameleon Attack},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3617553.3617888,
author = {Russo, Enrico and Ribaudo, Marina and Orlich, Alessandro and Longo, Giacomo and Armando, Alessandro},
title = {Cyber Range and Cyber Defense Exercises: Gamification Meets University Students},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617553.3617888},
doi = {10.1145/3617553.3617888},
abstract = {In the last decade, gamification has emerged as a valid alternative to more traditional learning processes both in academia and for professional training.  
Gamification has been successfully implemented in various disciplines to enhance the enjoyment and engagement of learning. This result can be achieved by providing challenges and quests, incentivizing task completion, and using role-playing games where learners assume different roles and perform tasks within a story format. In the case of cybersecurity, gamification can be introduced thanks to Capture The Flag (CTF) competitions or within virtual environments known as Cyber Ranges, where participants can test their skills on simulated networks, ICT systems, and other critical infrastructures. 
In this paper, we describe our experience with a cyber defender training activity proposed to computer science and computer engineering students. We organized lectures on cybersecurity, oriented towards developing problem-solving and practical skills. Then, we introduced gamification by running two on-site competitions: a Jeopardy CTF and a Cyber Defense Exercise.},
booktitle = {Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
pages = {29–37},
numpages = {9},
keywords = {cybersecurity education, cyber range, Gamification},
location = {San Francisco, CA, USA},
series = {Gamify 2023}
}

@proceedings{10.1145/3655693,
title = {EICC '24: Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xanthi, Greece}
}

@inproceedings{10.1145/3366423.3380092,
author = {Chapuis, Bertil and Omolola, Olamide and Cherubini, Mauro and Humbert, Mathias and Huguenin, K\'{e}vin},
title = {An Empirical Study of the Use of Integrity Verification Mechanisms for Web Subresources},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380092},
doi = {10.1145/3366423.3380092},
abstract = {Web developers can (and do) include subresources such as scripts, stylesheets and images in their webpages. Such subresources might be stored on content delivery networks (CDNs). This practice creates security and privacy risks, should a subresource be corrupted. The subresource integrity (SRI) recommendation, released in mid-2016 by the W3C, enables developers to include digests in their webpages in order for web browsers to verify the integrity of subresources before loading them. In this paper, we conduct the first large-scale longitudinal study of the use of SRI on the Web by analyzing massive crawls (≈ 3B URLs) of the Web over the last 3.5 years. Our results show that the adoption of SRI is modest (≈), but grows at an increasing rate and is highly influenced by the practices of popular library developers (e.g., Bootstrap) and CDN operators (e.g., jsDelivr). We complement our analysis about SRI with a survey of web developers (N=): It shows that a substantial proportion of developers know SRI and understand its basic functioning, but most of them ignore important aspects of the recommendation. The results of the survey also show that the integration of SRI by developers is mostly manual – hence not scalable and error prone. This calls for a better integration of SRI in build tools.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {34–45},
numpages = {12},
keywords = {web security, subresource integrity, common crawl},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3664476.3670899,
author = {Skopik, Florian and Akhras, Benjamin and Woisetschl\"{a}ger, Elisabeth and Andresel, Medina and Wurzenberger, Markus and Landauer, Max},
title = {On the Application of Natural Language Processing for Advanced OSINT Analysis in Cyber Defence},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670899},
doi = {10.1145/3664476.3670899},
abstract = {Open Source Intelligence (OSINT), in addition to closed military sources, provides timely information on emerging cyber attack techniques, attacker groups, changes in IT products, policy updates, recent events, and much more. Often, dozens of analysts scour hundreds of sources to gather, categorize, cluster, and prioritize news items, delivering the most pertinent information to decision makers. However, the sheer volume of sources and news items is continually expanding, making manual searches increasingly challenging. Moreover, the format and presentation of this information vary widely, with each blog entry, threat report, discussion forum, and mailing list item appearing differently, further complicating parsing and extracting relevant data. The research projects NEWSROOM and EUCINF, under the European Defence Fund (EDF), focus on leveraging Natural Language Processing (NLP) and Artificial Intelligence (AI) to enhance mission-oriented cyber situational awareness. These EDF initiatives are instrumental in advancing Taranis AI, a tool designed to categorize news items using machine learning algorithms and extract pertinent entities like company names, products, CVEs, and attacker groups. This enables the indexing and labeling of content, facilitating the identification of relationships and grouping of news items related to the same events – a crucial step in crafting cohesive "stories." These stories enable human analysts to swiftly capture the most significant current "hot topics", alleviating them from the task of consolidating or filtering redundant information from various sources. Taranis AI further enhances its capabilities by automatically generating summaries of reports and stories, and implementing a collaborative ranking system, among other features. This paper serves as an introduction to Taranis AI, exploring its NLP advancements and their practical applications. Additionally, it discusses lessons learned from its implementation and outlines future directions for research and development.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {71},
numpages = {10},
keywords = {NLP, OSINT analysis, cyber defence, situational awareness},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/2885990.2885994,
author = {Whitman, Michael and Mattord, Herbert},
title = {Ongoing threats to information protection},
year = {2015},
isbn = {9781450340496},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2885990.2885994},
doi = {10.1145/2885990.2885994},
abstract = {The threat landscape facing the use of information systems is constantly changing. This short summary of a recent survey of the threats to information protection provides a concise summary of the perceptions of number of current practitioners and how the organizations with which they are associated perceive this evolving threat environment.},
booktitle = {Proceedings of the 2015 Information Security Curriculum Development Conference},
articleno = {4},
numpages = {2},
keywords = {threats, information security},
location = {Kennesaw, Georgia},
series = {InfoSec '15}
}

@inproceedings{10.1145/3219788.3219804,
author = {Wu, Siyan and Tong, Xiaojun and Wang, Wei and Xin, Guodong and Wang, Bailing and Zhou, Qi},
title = {Website Defacements Detection Based on Support Vector Machine Classification Method},
year = {2018},
isbn = {9781450363938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219788.3219804},
doi = {10.1145/3219788.3219804},
abstract = {Website defacements can inflict significant harm on the website owner through the loss of reputation, the loss of money, or the leakage of information. Due to the complexity and diversity of all kinds of web application systems, especially a lack of necessary security maintenance, website defacements increased year by year. In this paper, we focus on detecting whether the website has been defaced by extracting website features and website embedded trojan features. We use three kinds of classification learning algorithms which include Gradient Boosting Decision Tree (GBDT), Random Forest (RF) and Support Vector Machine (SVM) to do the classification experiments, and experimental results show that Support Vector Machine classifier performed better than two other classifiers. It can achieve an overall accuracy of 95%-96% in detecting website defacements.},
booktitle = {Proceedings of the 2018 International Conference on Computing and Data Engineering},
pages = {62–66},
numpages = {5},
keywords = {website defacements, machine learning, feature extract, detection, Support Vector Machine},
location = {Shanghai, China},
series = {ICCDE '18}
}

@inproceedings{10.1145/2976749.2978362,
author = {Juels, Ari and Kosba, Ahmed and Shi, Elaine},
title = {The Ring of Gyges: Investigating the Future of Criminal Smart Contracts},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978362},
doi = {10.1145/2976749.2978362},
abstract = {Thanks to their anonymity (pseudonymity) and elimination of trusted intermediaries, cryptocurrencies such as Bitcoin have created or stimulated growth in many businesses and communities. Unfortunately, some of these are criminal, e.g., money laundering, illicit marketplaces, and ransomware. Next-generation cryptocurrencies such as Ethereum will include rich scripting languages in support of smart contracts, programs that autonomously intermediate transactions. In this paper, we explore the risk of smart contracts fueling new criminal ecosystems. Specifically, we show how what we call criminal smart contracts (CSCs) can facilitate leakage of confidential information, theft of cryptographic keys, and various real-world crimes (murder, arson, terrorism).We show that CSCs for leakage of secrets (a la Wikileaks) are efficiently realizable in existing scripting languages such as that in Ethereum. We show that CSCs for theft of cryptographic keys can be achieved using primitives, such as Succinct Non-interactive ARguments of Knowledge (SNARKs), that are already expressible in these languages and for which efficient supporting language extensions are anticipated. We show similarly that authenticated data feeds, an emerging feature of smart contract systems, can facilitate CSCs for real-world crimes (e.g., property crimes).Our results highlight the urgency of creating policy and technical safeguards against CSCs in order to realize the promise of smart contracts for beneficial goals.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {283–295},
numpages = {13},
keywords = {ethereum, criminal smart contracts},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3140368.3140372,
author = {Allodi, Luca and Etalle, Sandro},
title = {Towards Realistic Threat Modeling: Attack Commodification, Irrelevant Vulnerabilities, and Unrealistic Assumptions},
year = {2017},
isbn = {9781450352031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3140368.3140372},
doi = {10.1145/3140368.3140372},
abstract = {Current threat models typically consider all possible ways an attacker can penetrate a system and assign probabilities to each path according to some metric (e.g. time-to-compromise). In this paper we discuss how this view hinders the realness of both technical (e.g. attack graphs) and strategic (e.g. game theory) approaches of current threat modeling, and propose to steer away by looking more carefully at attack characteristics and attacker environment. We use a toy threat model for ICS attacks to show how a realistic view of attack instances can emerge from a simple analysis of attack phases and attacker limitations.},
booktitle = {Proceedings of the 2017 Workshop on Automated Decision Making for Active Cyber Defense},
pages = {23–26},
numpages = {4},
keywords = {vulnerabilities, threat modeling, attacker capabilities},
location = {Dallas, Texas, USA},
series = {SafeConfig '17}
}

@inproceedings{10.1145/2933575.2934579,
author = {Herlihy, Maurice and Moir, Mark},
title = {Blockchains and the Logic of Accountability: Keynote Address},
year = {2016},
isbn = {9781450343916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2933575.2934579},
doi = {10.1145/2933575.2934579},
booktitle = {Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science},
pages = {27–30},
numpages = {4},
location = {New York, NY, USA},
series = {LICS '16}
}

@proceedings{10.1145/3617553,
title = {Gamify 2023: Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Program Committee, we are pleased to present the proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation (Gamify 2023). The workshop is virtually co-located with the 2023 edition of the ESEC/FSE conference, held in San Francisco (CA, USA). The workshop will be held online only the 4th of December 2023.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3220267.3220269,
author = {Latib, Marlina Abdul and Ismail, Saiful Adli and Yusop, Othman Mohd and Magalingam, Pritheega and Azmi, Azri},
title = {Analysing Log Files For Web Intrusion Investigation Using Hadoop},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220269},
doi = {10.1145/3220267.3220269},
abstract = {The process of analyzing large amount of data from the log file helps organization to identify the web intruders' activities as well as the vulnerabilities of the website. However, analyzing them is totally a great challenge as the process is time consuming and sometimes can be inefficient. Existing or traditional log analyzers may not able to analyze such big chunk of data. Therefore, the aim of this research is to produce an analysis result for web intrusion investigation in Big Data environment. In this study, web log was analyzed based on attacks that are captured through web server log files. The web log was cleaned and refined through a log-preprocessing program before it was analyzed. An experimental simulation was conducted using Hadoop framework to produce the required analysis results. The results of this experimental simulation indicate that Hadoop application is able to produce analysis results from large size web log files in order to assist the web intrusion investigation. Besides that, the execution time performance analysis shows that the total execution time will not increase linearly with the size of the data. This study also provides solution on visualizing the analysis result using Power View and Hive.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {12–21},
numpages = {10},
keywords = {web log file, web intrusion, log pre-processing, Hadoop, Big Data},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@inproceedings{10.1145/2713579.2713582,
author = {Liu, Yang and Zhang, Jing and Sarabi, Armin and Liu, Mingyan and Karir, Manish and Bailey, Michael},
title = {Predicting Cyber Security Incidents Using Feature-Based Characterization of Network-Level Malicious Activities},
year = {2015},
isbn = {9781450333412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2713579.2713582},
doi = {10.1145/2713579.2713582},
abstract = {This study offers a first step toward understanding the extent to which we may be able to predict cyber security incidents (which can be of one of many types) by applying machine learning techniques and using externally observed malicious activities associated with network entities, including spamming, phishing, and scanning, each of which may or may not have direct bearing on a specific attack mechanism or incident type. Our hypothesis is that when viewed collectively, malicious activities originating from a network are indicative of the general cleanness of a network and how well it is run, and that furthermore, collectively they exhibit fairly stable and thus predictive behavior over time. To test this hypothesis, we utilize two datasets in this study: (1) a collection of commonly used IP address-based/host reputation blacklists (RBLs) collected over more than a year, and (2) a set of security incident reports collected over roughly the same period. Specifically, we first aggregate the RBL data at a prefix level and then introduce a set of features that capture the dynamics of this aggregated temporal process. A comparison between the distribution of these feature values taken from the incident dataset and from the general population of prefixes shows distinct differences, suggesting their value in distinguishing between the two while also highlighting the importance of capturing dynamic behavior (second order statistics) in the malicious activities. These features are then used to train a support vector machine (SVM) for prediction. Our preliminary results show that we can achieve reasonably good prediction performance over a forecasting window of a few months.},
booktitle = {Proceedings of the 2015 ACM International Workshop on International Workshop on Security and Privacy Analytics},
pages = {3–9},
numpages = {7},
keywords = {time-series data, temporal pattern, prediction, network security, network reputation},
location = {San Antonio, Texas, USA},
series = {IWSPA '15}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

